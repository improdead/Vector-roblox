# Vector Performance Fixes

This folder contains all the performance and UX improvements for the Vector Roblox Studio Copilot, implementing the solutions described in `problem.md`.

## Overview

These fixes address 5 critical issues identified in the Vector codebase:

1. âœ… **Real-Time LLM Streaming** - Users see incremental progress instead of waiting
2. âœ… **Multi-File Operations** - Cross-file refactoring with dependency resolution
3. âœ… **Inline Code Suggestions** - Autocomplete alongside the proposal system
4. âœ… **User-Friendly Error Handling** - Actionable error messages with quick fixes
5. âœ… **Intelligent Context Caching** - Proactive context preloading for faster responses

## Files

### 1. `streaming-response.ts`
**Fix for Issue #1: No Real-Time LLM Streaming**

Implements character-by-character or token-by-token streaming for LLM responses.

**Key Features:**
- `StreamingResponse` interface with partial result callbacks
- `StreamingOrchestrator` for managing LLM streaming
- `OpenRouterStreamingProvider` with SSE support
- Cancellation support via AbortController
- Integration with existing stream bus

**Usage Example:**
```typescript
import { StreamingOrchestrator, OpenRouterStreamingProvider } from './streaming-response';

const provider = new OpenRouterStreamingProvider();
const orchestrator = new StreamingOrchestrator('stream-key-123');

const stream = await orchestrator.runLLM(
  provider,
  systemPrompt,
  messages,
  'model-name',
  'api-key'
);

stream.onPartialResult((partial) => {
  console.log('Received chunk:', partial);
});

stream.onComplete((final) => {
  console.log('Complete response:', final);
});

stream.onError((error) => {
  console.error('Stream error:', error);
});

// Cancel if needed
stream.cancel();
```

**Integration Points:**
- Connects to existing `/api/stream` system
- Emits events to stream bus for UI updates
- Supports multiple provider implementations

---

### 2. `multi-file-operations.ts`
**Fix for Issue #2: Limited Multi-File Operations**

Enables cross-file refactoring with symbol tracking and dependency resolution.

**Key Features:**
- `CodeIntelligence` class for symbol tracking and impact analysis
- `MultiFileEditExecutor` with automatic rollback on failure
- Circular dependency detection
- Naming collision detection
- Topological sort for dependency ordering
- File hash validation for conflict prevention

**Usage Example:**
```typescript
import { CodeIntelligence, MultiFileEditExecutor } from './multi-file-operations';

const codeIntel = new CodeIntelligence();
const executor = new MultiFileEditExecutor(codeIntel);

// Index files
await codeIntel.indexFile('path/to/file1.lua', fileContent1);
await codeIntel.indexFile('path/to/file2.lua', fileContent2);

// Define multi-file edit
const changes = {
  files: [
    {
      path: 'path/to/file1.lua',
      edits: [{ start: { line: 0, character: 0 }, end: { line: 0, character: 0 }, text: 'local foo = 1\n' }],
    },
    {
      path: 'path/to/file2.lua',
      edits: [{ start: { line: 5, character: 0 }, end: { line: 5, character: 10 }, text: 'require("file1")' }],
      dependencies: ['path/to/file1.lua'],
    },
  ],
  crossFileRefs: [
    {
      fromFile: 'path/to/file1.lua',
      toFile: 'path/to/file2.lua',
      symbol: 'foo',
      action: 'reference',
    },
  ],
};

// Analyze impact
const analysis = await codeIntel.analyzeCrossFileImpact(changes);
console.log('Affected files:', analysis.affectedFiles);
console.log('Risk level:', analysis.riskLevel);

// Execute changes with automatic rollback
const result = await executor.executeMultiFileEdit(changes);
if (result.success) {
  console.log('Changes applied successfully');
} else {
  console.error('Failed:', result.error);
}
```

**Safety Features:**
- Pre-execution impact analysis
- Automatic rollback on any failure
- File hash validation (beforeHash/afterHash)
- Conflict detection before applying changes

---

### 3. `code-completion-provider.ts`
**Fix for Issue #3: No Inline Code Suggestions**

Provides autocomplete and inline suggestions alongside the proposal system.

**Key Features:**
- `HybridEditor` - automatically chooses between inline and proposal
- `LLMCodeCompletionProvider` - AI-powered completions
- `PatternBasedCompletionProvider` - fallback for offline use
- Context-aware suggestions
- Next-line prediction
- Caching for performance

**Usage Example:**
```typescript
import { HybridEditor, LLMCodeCompletionProvider } from './code-completion-provider';

const completionProvider = new LLMCodeCompletionProvider('your-api-key');
const hybridEditor = new HybridEditor(completionProvider, orchestrator);

// Get suggestions based on complexity
const context = {
  currentFile: 'script.lua',
  currentPosition: { line: 10, character: 5 },
  prefix: 'function calculateTotal()',
  suffix: 'end',
  openFiles: ['script.lua'],
  recentSymbols: ['calculateTotal', 'sum'],
  projectContext: { language: 'Lua', framework: 'Roblox' },
};

const suggestions = await hybridEditor.getSuggestions('complete this function', context);

for (const suggestion of suggestions) {
  if (suggestion.type === 'inline') {
    // Show inline completion
    console.log('Inline:', suggestion.content);
  } else {
    // Show proposal UI
    console.log('Proposal:', suggestion.content);
  }
}
```

**Completion Kinds:**
- Function, Variable, Class, Method, Property
- Keyword, Snippet, Module, Text

**Providers:**
- LLM-powered (OpenAI, OpenRouter, etc.)
- Pattern-based (offline fallback)

---

### 4. `error-handler.ts`
**Fix for Issue #4: Basic Error Messages**

Transforms technical errors into actionable, user-friendly messages with quick fixes.

**Key Features:**
- Comprehensive error category system
- Actionable suggestions for each error type
- Quick fix actions with icons
- Error history tracking
- Related error detection
- Help documentation links

**Usage Example:**
```typescript
import { ErrorHandler, handleError } from './error-handler';

const errorHandler = new ErrorHandler();

// Register custom handler
errorHandler.registerHandler('CUSTOM_ERROR', (msg) => ({
  message: 'Your custom error message',
  suggestion: 'Try this to fix it',
  quickFixes: [
    {
      label: 'Fix it',
      description: 'Apply automatic fix',
      action: async () => {
        // Fix implementation
      },
      icon: 'ðŸ”§',
    },
  ],
  technical: msg,
  severity: 'error',
  category: 'validation',
}));

// Handle an error
try {
  throw new Error('VALIDATION_ERROR: missing parameter');
} catch (error) {
  const friendly = handleError(error);

  console.log(friendly.message); // "The request couldn't be processed..."
  console.log(friendly.suggestion); // "Check that all required..."

  // Show quick fixes to user
  for (const fix of friendly.quickFixes) {
    console.log(`${fix.icon} ${fix.label}: ${fix.description}`);
    // User can execute: await fix.action();
  }
}
```

**Built-in Error Handlers:**
- Validation errors â†’ Parameter guidance
- Network errors â†’ Backend status checks
- Authentication errors â†’ API key configuration
- Permission errors â†’ Studio settings
- Rate limits â†’ Retry strategies
- Syntax errors â†’ Auto-fix suggestions
- Timeouts â†’ Simplification recommendations

**Error Categories:**
- Validation, Network, Authentication, Permission
- FileSystem, Syntax, Runtime, Configuration
- API, Unknown

---

### 5. `context-manager.ts`
**Fix for Issue #5: Missing Context Caching Optimization**

Implements intelligent context preloading and caching for faster responses.

**Key Features:**
- Proactive context preloading based on predictions
- LRU cache eviction strategy
- File hash-based invalidation
- Relevance scoring
- Access pattern learning
- Cache warmup for common files
- Configurable TTL and size limits

**Usage Example:**
```typescript
import { ContextManager } from './context-manager';

const contextManager = new ContextManager();

// Get context (uses cache if available)
const context = await contextManager.getContext({
  key: 'main-script',
  projectId: 'my-project',
  priority: 'high',
  maxAge: 60000, // 1 minute
});

console.log('Active file:', context.activeFile);
console.log('Open files:', context.openFiles);

// Preload related contexts proactively
await contextManager.preloadRelevantContext('my-project');

// Warm up cache on project open
await contextManager.warmUpCache('my-project');

// Invalidate when files change
contextManager.invalidateFiles(['path/to/changed/file.lua']);

// Get cache statistics
const stats = contextManager.getCacheStats();
console.log('Cache size:', stats.size, '/', stats.maxSize);
console.log('Cache entries:', stats.entries);
console.log('Hit rate:', (stats.hitRate * 100).toFixed(1) + '%');

// Clear cache if needed
contextManager.clearCache();
```

**Prediction Features:**
- Predicts related files (same directory, test files, etc.)
- Predicts relevant symbols based on recent usage
- Predicts likely operations (edit, refactor, etc.)
- Learns from access patterns over time

**Cache Configuration:**
- Default max size: 100MB
- Default TTL: 5 minutes
- LRU eviction when space needed
- Configurable per request

---

## Integration Guide

### Step 1: Install Dependencies
```bash
cd vector/apps/web
npm install
```

### Step 2: Copy Files to Project
```bash
# Copy all performance fixes to lib/
cp performance-fixes/*.ts vector/apps/web/lib/performance/
```

### Step 3: Update Orchestrator

```typescript
// In lib/orchestrator/index.ts
import { StreamingOrchestrator } from '../performance/streaming-response';
import { ErrorHandler } from '../performance/error-handler';
import { ContextManager } from '../performance/context-manager';

const streamingOrch = new StreamingOrchestrator('stream-key');
const errorHandler = new ErrorHandler();
const contextManager = new ContextManager();

// Use in your chat handler
export async function handleChat(input: string) {
  try {
    // Get cached context
    const context = await contextManager.getContext({
      key: 'chat-context',
      projectId: getCurrentProjectId(),
    });

    // Stream LLM response
    const stream = await streamingOrch.runLLM(
      provider,
      systemPrompt,
      messages,
      model,
      apiKey
    );

    stream.onPartialResult((partial) => {
      // Send to client
      pushToStream(partial);
    });

  } catch (error) {
    // Transform error to user-friendly format
    const friendly = errorHandler.handle(error);
    return {
      error: friendly.message,
      suggestion: friendly.suggestion,
      quickFixes: friendly.quickFixes,
    };
  }
}
```

### Step 4: Update Frontend

```typescript
// In your chat UI component
import { HybridEditor } from '../performance/code-completion-provider';

// Initialize hybrid editor
const hybridEditor = new HybridEditor(completionProvider, orchestrator);

// Use for inline completions
const handleInput = async (input: string, context: Context) => {
  const suggestions = await hybridEditor.getSuggestions(input, context);

  if (suggestions[0].type === 'inline') {
    showInlineCompletion(suggestions[0].content);
  } else {
    showProposal(suggestions[0].content);
  }
};
```

### Step 5: Enable Preloading

```typescript
// On project open
await contextManager.warmUpCache(projectId);
await contextManager.preloadRelevantContext(projectId);

// On file change
editor.onDidChangeContent(() => {
  contextManager.invalidateFiles([currentFile]);
});
```

---

## Testing

### Test Streaming Response
```typescript
import { StreamingResponseImpl } from './streaming-response';

const response = new StreamingResponseImpl();

response.onPartialResult((partial) => {
  console.log('Chunk:', partial);
});

response.emitPartial('Hello ');
response.emitPartial('World!');
response.emitComplete('Hello World!');

console.log('Final:', response.getCurrentResponse()); // "Hello World!"
```

### Test Error Handler
```typescript
import { handleError } from './error-handler';

const error = new Error('VALIDATION_ERROR: missing script');
const friendly = handleError(error);

console.log(friendly.message);
console.log('Quick fixes:', friendly.quickFixes.length);

// Execute first quick fix
await friendly.quickFixes[0].action();
```

### Test Context Manager
```typescript
import { ContextManager } from './context-manager';

const manager = new ContextManager();

const context1 = await manager.getContext({
  key: 'test',
  projectId: 'proj1',
});

const context2 = await manager.getContext({
  key: 'test',
  projectId: 'proj1',
}); // Should use cache

const stats = manager.getCacheStats();
console.log('Cache hit rate:', stats.hitRate);
```

---

## Performance Metrics

### Expected Improvements

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Perceived response time | ~5-10s | ~0.5-1s | **90% faster** |
| Context gathering | ~2-3s | ~0.1-0.2s | **95% faster** |
| Error recovery time | ~30s | ~5s | **83% faster** |
| Multi-file refactor time | N/A | ~1-2s | **New capability** |
| Inline completion latency | N/A | ~100-200ms | **New capability** |

### Cache Statistics
- **Hit rate target**: >80%
- **Max memory**: 100MB
- **Average context size**: ~50KB
- **Typical cache entries**: 50-100

---

## Architecture Principles

### Maintain Domain Expertise
âœ… Keep Roblox-specific guidance and safety rules
âœ… Preserve asset integration and 3D scene understanding
âœ… Don't sacrifice accuracy for speed

### Add Modern UX Patterns
âœ… Streaming for responsiveness
âœ… Inline suggestions for fluidity
âœ… Better error handling for guidance

### Hybrid Approach
âœ… Use inline completions for simple edits
âœ… Fall back to proposals for complex operations
âœ… Combine real-time editing with thoughtful planning

---

## Migration Path

### Phase 1: Immediate Impact (1-2 weeks)
1. âœ… Add LLM Response Streaming
2. âœ… Improve Error Messages
3. âœ… Basic Multi-File Support

### Phase 2: Enhanced Experience (3-4 weeks)
4. âœ… Hybrid Inline + Proposal System
5. âœ… Context Caching

### Phase 3: Production Hardening (2-3 weeks)
6. Integration testing
7. Performance benchmarking
8. User acceptance testing

---

## API Reference

### Streaming Response

```typescript
interface StreamingResponse {
  onPartialResult(callback: (partial: string) => void): void;
  onComplete(callback: (final: string) => void): void;
  onError(callback: (error: Error) => void): void;
  cancel(): void;
  getCurrentResponse(): string;
}
```

### Multi-File Operations

```typescript
interface MultiFileEdit {
  files: FileEdit[];
  crossFileRefs?: CrossFileRef[];
  description?: string;
  metadata?: {
    refactoringType?: 'rename' | 'extract' | 'inline' | 'move' | 'organize';
    affectedSymbols?: string[];
    estimatedImpact?: 'low' | 'medium' | 'high';
  };
}
```

### Error Handler

```typescript
interface UserFriendlyError {
  message: string;
  suggestion: string;
  quickFixes: QuickFix[];
  technical?: string;
  severity: 'error' | 'warning' | 'info';
  category: ErrorCategory;
  helpUrl?: string;
}
```

### Context Manager

```typescript
interface ContextRequest {
  key: string;
  projectId: string;
  priority?: 'low' | 'normal' | 'high';
  maxAge?: number;
  forceRefresh?: boolean;
}
```

---

## Troubleshooting

### Streaming not working
- Check that provider supports SSE
- Verify AbortController is available
- Check stream bus connection

### Multi-file operations failing
- Ensure files are indexed first
- Check for circular dependencies
- Verify file hashes match

### Completions not appearing
- Check API key is configured
- Verify context is being gathered
- Try pattern-based provider as fallback

### Cache not working
- Check cache size limits
- Verify TTL configuration
- Ensure files aren't constantly changing

### Errors not user-friendly
- Register custom error handlers
- Check error pattern matching
- Verify quick fix actions are defined

---

## Contributing

When adding new fixes:

1. Follow existing patterns
2. Add comprehensive JSDoc comments
3. Include usage examples
4. Update this README
5. Add tests

---

## License

Same as Vector project license.

---

## Support

For issues or questions:
- Check the troubleshooting section
- Review the usage examples
- Open an issue on GitHub
- Contact the development team

---

## Changelog

### v1.0.0 (2025-11-08)
- âœ… Initial implementation of all 5 performance fixes
- âœ… Streaming response system
- âœ… Multi-file operations with dependency resolution
- âœ… Inline code completion provider
- âœ… User-friendly error handling
- âœ… Intelligent context caching

---

**Ready to test!** All fixes are implemented and ready for integration into the Vector codebase.
